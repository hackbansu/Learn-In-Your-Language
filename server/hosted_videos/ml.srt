1
00:00:00.000 --> 00:00:11.000
इस और अगले कुछ वीडियो में, मैं वर्गीकरण समस्याओं के बारे में बात करना शुरू करना चाहता हूं, जहां वेरिएबल वाई जिसे आप भविष्यवाणी करना चाहते हैं, मूल्यवान है।

2
00:00:11.000 --> 00:00:22.000
हम लॉजिस्टिक रिग्रेशन नामक एक एल्गोरिदम विकसित करेंगे, जो आज के सबसे लोकप्रिय और सबसे व्यापक रूप से उपयोग किए जाने वाले सीखने वाले एल्गोरिदम में से एक है।

3
00:00:22.000 --> 00:00:26.000
वर्गीकरण समस्याओं के कुछ उदाहरण यहां दिए गए हैं।

4
00:00:26.000 --> 00:00:33.000
इससे पहले हमने वर्गीकरण समस्या के उदाहरण के रूप में ईमेल स्पैम वर्गीकरण के बारे में बात की थी।

5
00:00:33.000 --> 00:00:36.000
एक और उदाहरण ऑनलाइन लेनदेन वर्गीकृत किया जाएगा।

6
00:00:36.000 --> 00:00:51.000
इसलिए यदि आपके पास ऐसी वेबसाइट है जो सामान बेचती है और यदि आप जानना चाहते हैं कि कोई विशेष लेनदेन धोखाधड़ी है या नहीं, चाहे कोई चोरी किए गए क्रेडिट कार्ड का उपयोग कर रहा हो या उपयोगकर्ता का पासवर्ड चुरा लिया हो।

7
00:00:51.000 --> 00:00:53.000
एक और वर्गीकरण समस्या है।

8
00:00:53.000 --> 00:01:02.000
और इससे पहले हमने ट्यूमर को कैंसर, घातक या सौम्य ट्यूमर के रूप में वर्गीकृत करने के उदाहरण के बारे में भी बात की थी।

9
00:01:02.000 --> 00:01:17.000
इन सभी समस्याओं में चर जिसे हम भविष्यवाणी करने की कोशिश कर रहे हैं वह एक चर वाई है जिसे हम शून्य या एक, या तो स्पैम या स्पैम, धोखाधड़ी या धोखाधड़ी नहीं, संबंधित घातक या सौम्य के रूप में सोच सकते हैं।

10
00:01:17.000 --> 00:01:28.000
कक्षा के लिए एक और नाम जिसे हम शून्य से दर्शाते हैं वह नकारात्मक वर्ग है, और उस वर्ग के लिए दूसरा नाम जिसे हम एक के साथ दर्शाते हैं वह सकारात्मक वर्ग है।

11
00:01:28.000 --> 00:01:36.000
तो शून्य हम सौम्य ट्यूमर के रूप में दर्शाते हैं, और एक, सकारात्मक वर्ग हम एक घातक ट्यूमर को दर्शाते हैं।

12
00:01:36.000 --> 00:01:40.000
काम के दो वर्गों, स्पैम नहीं स्पैम और इतने पर.

13
00:01:40.000 --> 00:01:56.000
दो वर्गों का काम सकारात्मक और शून्य से नकारात्मक और एक कुछ हद तक मनमाना है और यह वास्तव में कोई फर्क नहीं पड़ता है, लेकिन अक्सर यह अंतर्ज्ञान है कि एक नकारात्मक वर्ग एक घातक ट्यूमर की अनुपस्थिति की तरह कुछ की अनुपस्थिति को संदेश दे रहा है।

14
00:01:56.000 --> 00:02:10.000
जबकि एक सकारात्मक वर्ग उस चीज़ की उपस्थिति को व्यक्त कर रहा है जिसे हम ढूंढ रहे हैं, लेकिन इसकी परिभाषा नकारात्मक है और जो सकारात्मक है, कुछ हद तक मनमाना है और इससे कोई फर्क नहीं पड़ता।

15
00:02:10.000 --> 00:02:17.000
अभी के लिए हम केवल दो वर्गों शून्य और एक के साथ वर्गीकरण समस्याओं से शुरू करने जा रहे हैं।

16
00:02:17.000 --> 00:02:26.000
बाद में हम बहु श्रेणी की समस्याओं के बारे में भी बात करेंगे, जहां y चार मान शून्य, एक, दो और तीन ले सकता है।

17
00:02:26.000 --> 00:02:29.000
इसे एक मल्टीक्लास वर्गीकरण समस्या कहा जाता है।

18
00:02:29.000 --> 00:02:39.000
लेकिन अगले कुछ वीडियो के लिए, चलो दो वर्ग या बाइनरी वर्गीकरण समस्या से शुरू करते हैं और हम बाद में मल्टीक्लास सेटिंग के बारे में चिंता करेंगे।

19
00:02:39.000 --> 00:02:43.000
तो हम एक वर्गीकरण एल्गोरिदम कैसे विकसित करते हैं?

20
00:02:43.000 --> 00:02:51.000
ट्यूमर को घातक या सौम्य के रूप में वर्गीकृत करने के लिए वर्गीकरण कार्य के लिए प्रशिक्षण सेट का एक उदाहरण यहां दिया गया है।

21
00:02:51.000 --> 00:02:56.000
और ध्यान दें कि घातकता केवल दो मान लेती है, शून्य या नहीं, एक या हाँ।

22
00:02:56.000 --> 00:03:04.000
तो एक बात यह है कि हम इस प्रशिक्षण सेट को दे सकते हैं वह एल्गोरिदम लागू करना है जिसे हम पहले से ही जानते हैं।

23
00:03:04.000 --> 00:03:09.000
इस डेटा सेट पर रैखिक प्रतिगमन और बस डेटा को सीधी रेखा फिट करने का प्रयास करें।

24
00:03:09.000 --> 00:03:19.000
तो यदि आप इस प्रशिक्षण सेट को लेते हैं और इसे एक सीधी रेखा भरते हैं, तो शायद आपको ऐसी परिकल्पना मिलती है जो इस तरह दिखती है, है ना।

25
00:03:19.000 --> 00:03:21.000
तो यह मेरी परिकल्पना है।

26
00:03:21.000 --> 00:03:25.000
एच (एक्स) थीटा एक्स को स्थानांतरित करता है।

27
00:03:25.000 --> 00:03:34.000
यदि आप भविष्यवाणियों को एक चीज बनाना चाहते हैं जो आप करने का प्रयास कर सकते हैं तो क्लासिफायर आउटपुट को 0 पर थ्रेशोल्ड करें।

28
00:03:34.000 --> 00:03:37.000
5 जो एक ऊर्ध्वाधर अक्ष मान 0 पर है।

29
00:03:37.000 --> 00:03:42.000
5 और यदि परिकल्पना एक मान आउटपुट करती है जो 0 के बराबर से अधिक है।

30
00:03:42.000 --> 00:03:45.000
5 आप y = 1 ले सकते हैं।

31
00:03:45.000 --> 00:03:47.000
यदि यह 0 से कम है।

32
00:03:47.000 --> 00:03:50.000
5 आप y = 0 ले सकते हैं।

33
00:03:50.000 --> 00:03:54.000
चलो देखते हैं कि अगर हम ऐसा करते हैं तो क्या होता है।

34
00:03:54.000 --> 00:03:55.000
तो 0.

35
00:03:55.000 --> 00:04:01.000
5 और यही वह जगह है जहां थ्रेसहोल्ड है और यह इस तरह से रैखिक प्रतिगमन का उपयोग कर रहा है।

36
00:04:01.000 --> 00:04:07.000
इस बिंदु के दाईं ओर सब कुछ हम सकारात्मक क्रॉस के रूप में भविष्यवाणी करेंगे।

37
00:04:07.000 --> 00:04:09.000
क्योंकि आउटपुट मान 0 से अधिक है।

38
00:04:09.000 --> 00:04:17.000
5 ऊर्ध्वाधर अक्ष पर और उस बिंदु के बाईं ओर सब कुछ हम एक नकारात्मक मूल्य के रूप में भविष्यवाणी समाप्त कर देंगे।

39
00:04:17.000 --> 00:04:23.000
इस विशेष उदाहरण में, ऐसा लगता है कि रैखिक प्रतिगमन वास्तव में कुछ उचित कर रहा है।

40
00:04:23.000 --> 00:04:28.000
हालांकि यह एक वर्गीकरण टॉस है, हम में रुचि रखते हैं।

41
00:04:28.000 --> 00:04:31.000
लेकिन अब समस्या को थोड़ा सा बदलने की कोशिश करते हैं।

42
00:04:31.000 --> 00:04:39.000
मुझे क्षैतिज पहुंच को थोड़ा सा विस्तार करने दें और मान लें कि हमें दाईं ओर एक और प्रशिक्षण उदाहरण मिला है।

43
00:04:39.000 --> 00:04:47.000
ध्यान दें कि अतिरिक्त प्रशिक्षण उदाहरण, यह यहां से बाहर है, यह वास्तव में कुछ भी नहीं बदलता है, है ना।

44
00:04:47.000 --> 00:04:52.000
प्रशिक्षण सेट को देखते हुए यह स्पष्ट है कि एक अच्छी परिकल्पना क्या है।

45
00:04:52.000 --> 00:05:01.000
यहाँ कहीं के आसपास के अधिकार के लिए है कि अच्छी तरह से सब कुछ है, इस के अधिकार के लिए हम इस सकारात्मक भविष्यवाणी करनी चाहिए.

46
00:05:01.000 --> 00:05:19.000
बाईं ओर सब कुछ हमें शायद नकारात्मक के रूप में भविष्यवाणी करनी चाहिए क्योंकि इस प्रशिक्षण सेट से, ऐसा लगता है कि यहां के चारों ओर एक निश्चित मूल्य से बड़ा सभी ट्यूमर घातक हैं, और उस से छोटे सभी ट्यूमर कम से कम इस प्रशिक्षण सेट के लिए घातक नहीं हैं।

47
00:05:19.000 --> 00:05:29.000
लेकिन एक बार जब हमने यहां उस अतिरिक्त उदाहरण को जोड़ दिया है, यदि अब आप रैखिक प्रतिगमन चलाते हैं, तो आपको डेटा के लिए सीधी रेखा फिट मिलती है।

48
00:05:29.000 --> 00:05:32.000
यह शायद इस तरह दिख सकता है।

49
00:05:32.000 --> 00:05:35.000
और यदि आप 0 पर थ्रेसहोल्ड परिकल्पना जानते हैं।

50
00:05:35.000 --> 00:05:51.000
5, आप एक सीमा के साथ समाप्त होते हैं जो यहां के आसपास है, ताकि इस बिंदु के दाईं ओर सब कुछ आप सकारात्मक के रूप में भविष्यवाणी करते हैं और उस बिंदु के बाईं ओर सब कुछ आप नकारात्मक के रूप में भविष्यवाणी करते हैं।

51
00:05:51.000 --> 00:06:02.000
और यह रैखिक प्रतिगमन के लिए एक बहुत बुरी चीज है, ठीक है, क्योंकि आप जानते हैं कि ये हमारे सकारात्मक उदाहरण हैं, ये हमारे नकारात्मक उदाहरण हैं।

52
00:06:02.000 --> 00:06:15.000
यह स्पष्ट है कि हमें वास्तव में वहां कहीं भी दोनों को अलग करना चाहिए, लेकिन किसी भी तरह से दाईं ओर एक उदाहरण जोड़कर, यह उदाहरण वास्तव में हमें कोई नई जानकारी नहीं दे रहा है।

53
00:06:15.000 --> 00:06:20.000
मेरा मतलब है, सीखने वाले एल्गोरिदम के लिए कोई आश्चर्य नहीं होना चाहिए।

54
00:06:20.000 --> 00:06:25.000
यह उदाहरण यहां से बाहर निकलने का रास्ता घातक हो जाता है।

55
00:06:25.000 --> 00:06:38.000
लेकिन किसी भी तरह से उस उदाहरण के कारण रैखिक प्रतिगमन को इस मैजेंटा लाइन से डेटा में अपनी सीधी रेखा फिट करने के लिए यहां इस नीली रेखा तक बदल दिया गया, और इससे हमें एक खराब परिकल्पना मिलती है।

56
00:06:38.000 --> 00:06:44.000
इसलिए, वर्गीकरण समस्या के लिए रैखिक प्रतिगमन लागू करना अक्सर एक अच्छा विचार नहीं है।

57
00:06:44.000 --> 00:07:08.000
पहले उदाहरण में, इससे पहले कि मैंने इस अतिरिक्त प्रशिक्षण उदाहरण को जोड़ा, पहले रैखिक प्रतिगमन सिर्फ भाग्यशाली हो रहा था और हमें एक ऐसी अवधारणा मिली जो उस विशेष उदाहरण के लिए अच्छी तरह से काम करती थी, लेकिन आमतौर पर डेटा सेट पर रैखिक प्रतिगमन लागू करने से, आप भाग्यशाली हो सकते हैं लेकिन अक्सर यह एक अच्छा विचार नहीं है।

58
00:07:08.000 --> 00:07:13.000
इसलिए मैं वर्गीकरण समस्याओं के लिए रैखिक प्रतिगमन का उपयोग नहीं करता।

59
00:07:13.000 --> 00:07:22.000
यदि हम वर्गीकरण समस्या के लिए रैखिक प्रतिगमन का उपयोग करना चाहते हैं तो क्या होगा इसके बारे में एक और मजेदार बात यहां दी गई है।

60
00:07:22.000 --> 00:07:26.000
वर्गीकरण के लिए हम जानते हैं कि y या तो शून्य या एक है।

61
00:07:26.000 --> 00:07:40.000
लेकिन यदि आप रैखिक प्रतिगमन का उपयोग कर रहे हैं जहां परिकल्पना उन मानों को आउटपुट कर सकती है जो शून्य से एक या उससे कम से कम बड़ी हैं, भले ही आपके सभी प्रशिक्षण उदाहरणों में लेबल वाई शून्य या एक के बराबर हो।

62
00:07:40.000 --> 00:07:51.000
और यह अजीब लगता है कि भले ही हम जानते हैं कि लेबल शून्य होना चाहिए, एक ऐसा अजीब लगता है कि एल्गोरिदम शून्य से एक या बहुत छोटे से मूल्यों को आउटपुट कर सकता है।

63
00:07:51.000 --> 00:08:10.000
तो अगले कुछ वीडियो में हम क्या करेंगे, एक एल्गोरिदम विकसित करना है जिसे लॉजिस्टिक रिग्रेशन कहा जाता है, जिसमें संपत्ति है कि आउटपुट, लॉजिस्टिक रिग्रेशन की भविष्यवाणियां हमेशा शून्य और एक के बीच होती हैं, और यह एक से बड़ा नहीं होती है या शून्य से कम हो जाती है।

64
00:08:10.000 --> 00:08:28.000
और वैसे, रसद प्रतिगमन है, और हम इसे वर्गीकरण एल्गोरिदम के रूप में उपयोग करेंगे, कुछ, शायद कभी-कभी भ्रमित हो सकते हैं कि शब्द प्रतिगमन इस नाम में प्रकट होता है, भले ही लॉजिस्टिक रिग्रेशन वास्तव में एक वर्गीकरण एल्गोरिदम है।

65
00:08:28.000 --> 00:08:32.000
लेकिन यह सिर्फ एक नाम है जो ऐतिहासिक कारणों से दिया गया था।

66
00:08:32.000 --> 00:08:43.000
तो उस लॉजिस्टिक रिग्रेशन से भ्रमित न हों वास्तव में एक वर्गीकरण एल्गोरिदम है जिसे हम सेटिंग्स पर लागू करते हैं जहां लेबल वाई असतत मान है, जब यह शून्य या एक होता है।

67
00:08:43.000 --> 00:08:52.000
तो उम्मीद है कि अब आप जानते हैं कि, यदि आपके पास वर्गीकरण समस्या है, तो रैखिक प्रतिगमन का उपयोग करना एक अच्छा विचार नहीं है।

68
00:08:52.000 --> 00:08:60.000
अगले वीडियो में, हम लॉजिस्टिक रिग्रेशन एल्गोरिदम के विवरण का काम करना शुरू कर देंगे।

